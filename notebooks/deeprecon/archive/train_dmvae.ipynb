{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c086c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from fmri_reconstruction_with_dmvae.deeprecon.datasets.load import load_data\n",
    "from fmri_reconstruction_with_dmvae.deeprecon.datasets.align import get_train_data, get_test_data\n",
    "from fmri_reconstruction_with_dmvae.deeprecon.datasets.combine import conbine_cross_occurrences\n",
    "from fmri_reconstruction_with_dmvae.deeprecon.datasets.dataset import get_dataset\n",
    "\n",
    "\n",
    "from fmri_reconstruction_with_dmvae.models.dmvae import DMVAE\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037394a6",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c74bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/data/deeprecon/\")\n",
    "parser.add_argument(\"--output_path\", type=str, default=\"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/results/deeprecon/conversion/\")\n",
    "# parser.add_argument(\"--ckpt_path\", type=str, default=\"\")\n",
    "\n",
    "parser.add_argument(\"--subj_list\", nargs=\"+\", type=int, default=[1, 2])\n",
    "parser.add_argument(\"--n_samples\", type=int, default=2400)\n",
    "parser.add_argument(\"--is_normalized\", type=argparse.BooleanOptionalAction, default=True)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "parser.add_argument(\"--zp_dim\", type=int, default=256)\n",
    "parser.add_argument(\"--zs_dim\", type=int, default=768)\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=1024)\n",
    "parser.add_argument(\"--lr\", type=int, default=5e-4)\n",
    "parser.add_argument(\"--weight_decay\", type=int,default=1e-1)\n",
    "parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--all_subj_lambdas\", nargs=\"+\", type=int, default=[1, 1, 1, 1, 1, 1, 1, 1])\n",
    "parser.add_argument(\"--seed\", type=int, default=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1077c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d2fb1",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421400d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/data/deeprecon/\"\n",
    "subj_list = [1, 3, 4, 5]   # [1, 2, 3, 4, 5] \n",
    "\n",
    "n_samples = 2400\n",
    "\n",
    "# set needed repetitions\n",
    "rep = 1 if n_samples < 1200 else int(n_samples / 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6b0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load\n",
    "train_brain_data_dict, test_brain_data_dict, all_subj_num_voxels = load_data(data_path, subj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3a8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Align\n",
    "train_data, train_mean_dict, train_norm_dict = get_train_data(train_brain_data_dict, subj_list, rep, is_normalized=True)\n",
    "# ### Combine\n",
    "# train_data = conbine_cross_occurrences(train_data, subj_list)\n",
    "\n",
    "test_data = get_test_data(test_brain_data_dict, subj_list, train_mean_dict, train_norm_dict, is_normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767fed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset\n",
    "train_dataset, test_dataset = get_dataset(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ef7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DataLoader\n",
    "batch_size = 128\n",
    "g = torch.Generator()\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, generator=g)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc04f1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c27d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_dim = 256\n",
    "zs_dim = 768\n",
    "hidden_dim = 1024\n",
    "optimizer = optim.Adam\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-1\n",
    "\n",
    "model = DMVAE(subj_list, all_subj_num_voxels, zp_dim, zs_dim, hidden_dim, device=device, optimizer=optimizer, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e020f90",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db60e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recon_dict_batch(input_dict, model):\n",
    "    z_dict = {}\n",
    "    recon_dict_batch = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for subj in subj_list:\n",
    "            s = f\"{int(subj):02d}\"\n",
    "            z_dict[f\"zp{s}\"] = model.dist_dict[f\"q_zp{s}__x{s}\"].sample(input_dict, return_all=False) \n",
    "            z_dict[f\"zs__x{s}\"] = model.dist_dict[f\"q_zs__x{s}\"].sample(input_dict, return_all=False)\n",
    "        \n",
    "        z_dict[\"zs__x\"] = model.dist_dict[\"q_zs__x\"].sample(input_dict, return_all=False)\n",
    "\n",
    "        for subj_target in subj_list:\n",
    "            s_t = f\"{int(subj_target):02d}\"\n",
    "\n",
    "            recon_dict_batch[f\"joint_recon_x{s_t}\"] = model.dist_dict[f\"p_x{s_t}__zp{s_t}_zs\"].sample_mean(z_dict[f\"zp{s_t}\"] | z_dict[f\"zs__x\"]).cpu()\n",
    "            \n",
    "            for subj_source in subj_list:\n",
    "                s_s = f\"{int(subj_source):02d}\"\n",
    "\n",
    "                if s_t == s_s:\n",
    "                    recon_dict_batch[f\"self_recon_x{s_t}\"] = model.dist_dict[f\"p_x{s_t}__zp{s_t}_zs\"].sample_mean(z_dict[f\"zp{s_t}\"] | z_dict[f\"zs__x{s_s}\"]).cpu()\n",
    "                else:\n",
    "                    recon_dict_batch[f\"cross_recon_x{s_t}__x{s_s}\"] = model.dist_dict[f\"p_x{s_t}__zp{s_t}_zs\"].sample_mean(z_dict[f\"zp{s_t}\"] | z_dict[f\"zs__x{s_s}\"]).cpu()\n",
    "\n",
    "    return recon_dict_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44730f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for data in tqdm(train_dl):\n",
    "        input_dict = {}\n",
    "        lambda_dict = {}\n",
    "        \n",
    "        for subj in subj_list:\n",
    "            s = f\"{int(subj):02d}\"\n",
    "\n",
    "            input_dict[f\"x{s}\"] = data[f\"subj{s}\"].to(torch.float32).to(device)\n",
    "            lambda_dict[f\"lambda_{s}\"] = all_subj_lambdas[int(s)-1]\n",
    "\n",
    "        loss = model.train(input_dict | lambda_dict)\n",
    "        train_loss += loss * input_dict[f\"x{s}\"].size(0)\n",
    "        total_samples += input_dict[f\"x{s}\"].size(0)\n",
    "\n",
    "    train_loss = train_loss / total_samples\n",
    "    print('Epoch: {} Train loss: {:.4f}'.format(epoch, train_loss))\n",
    "    return train_loss\n",
    "\n",
    "def test(epoch):\n",
    "    test_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_input_dict_list = []\n",
    "    all_recon_dict_list = []\n",
    "    all_image_index_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_dl):\n",
    "            input_dict = {}\n",
    "            lambda_dict = {}\n",
    "            \n",
    "            for subj in subj_list:\n",
    "                s = f\"{int(subj):02d}\"\n",
    "                input_dict[f\"x{s}\"] = data[f\"subj{s}\"].to(torch.float32).to(device)\n",
    "                lambda_dict[f\"lambda_{s}\"] = all_subj_lambdas[int(s)-1]\n",
    "\n",
    "            loss = model.test(input_dict | lambda_dict)\n",
    "            test_loss += loss * input_dict[f\"x{s}\"].size(0)\n",
    "            total_samples += input_dict[f\"x{s}\"].size(0)\n",
    "\n",
    "            if epoch == epochs:\n",
    "                all_input_dict_list.append(input_dict)\n",
    "\n",
    "                recon_dict_batch = get_recon_dict_batch(input_dict, model)\n",
    "                all_recon_dict_list.append(recon_dict_batch)\n",
    "\n",
    "                all_image_index_list.append(data[\"image_index\"])\n",
    "\n",
    "    test_loss = test_loss / total_samples\n",
    "    print('Epoch: {} Test loss: {:.4f}'.format(epoch, test_loss))\n",
    "    return test_loss, all_input_dict_list, all_recon_dict_list, all_image_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 404740.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Test loss: 396098.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train loss: 394544.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Test loss: 391311.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train loss: 389816.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Test loss: 389000.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train loss: 385818.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Test loss: 386405.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train loss: 381745.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Test loss: 383988.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train loss: 378253.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Test loss: 382253.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train loss: 375026.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Test loss: 380793.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train loss: 372489.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Test loss: 379645.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train loss: 370043.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Test loss: 378581.7812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train loss: 367809.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Test loss: 377924.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Train loss: 365822.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Test loss: 377343.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Train loss: 363988.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Test loss: 376697.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Train loss: 362094.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Test loss: 376228.7812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Train loss: 360523.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Test loss: 375783.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Train loss: 358984.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Test loss: 375454.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Train loss: 357414.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Test loss: 375359.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Train loss: 355911.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Test loss: 375104.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Train loss: 354548.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Test loss: 374900.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Train loss: 353243.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Test loss: 374787.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Train loss: 351941.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Test loss: 374651.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "all_subj_lambdas = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "g.manual_seed(42)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss, all_input_dict_list, all_recon_dict_list, all_image_index_list = test(epoch)\n",
    "\n",
    "# model.save(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96eb7c4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a4c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_result_dict_list(all_result_dict_list):\n",
    "    collated_all_result_dict = {\n",
    "        key: torch.cat(\n",
    "            [chunk[key].to(dtype=torch.float32) for chunk in all_result_dict_list],\n",
    "            dim=0\n",
    "        ).cpu().numpy()\n",
    "        for key in all_result_dict_list[0].keys()\n",
    "    }\n",
    "    \n",
    "    return collated_all_result_dict\n",
    "\n",
    "def calculate_pattern_correlation(target_brain, recon_brain, label, rep=24):\n",
    "    sort_idx = np.argsort(label.flatten())\n",
    "    target_brain = target_brain[sort_idx]\n",
    "    recon_brain = recon_brain[sort_idx]\n",
    "    label = label[sort_idx]\n",
    "    unique_label = np.unique(label)\n",
    "\n",
    "    pattern_corr = []\n",
    "    for image_idx in unique_label:\n",
    "        target_pattern = target_brain[(label == image_idx).flatten(), :]\n",
    "        recon_pattern = recon_brain[(label == image_idx).flatten(), :]\n",
    "        \n",
    "        corrs = np.corrcoef(target_pattern, recon_pattern)[:rep, rep:]\n",
    "        corr = np.mean(corrs) \n",
    "\n",
    "        pattern_corr.append(corr)\n",
    "\n",
    "    return pattern_corr\n",
    "\n",
    "def calculate_profile_correlation(target_brain, recon_brain, label, rep=24):\n",
    "    sort_idx = np.argsort(label.flatten())\n",
    "    target_brain = target_brain[sort_idx]\n",
    "    recon_brain = recon_brain[sort_idx]\n",
    "\n",
    "    profile_corr = []\n",
    "    for voxel_idx in range(target_brain.shape[1]):\n",
    "        target_profile = target_brain[:, voxel_idx].reshape(rep, -1, order=\"F\")\n",
    "        recon_profile = recon_brain[:, voxel_idx].reshape(rep, -1, order=\"F\")\n",
    "        \n",
    "        corrs = np.corrcoef(target_profile, recon_profile)[:rep, rep:]\n",
    "        corr = np.mean(corrs) \n",
    "\n",
    "        profile_corr.append(corr)\n",
    "\n",
    "    return profile_corr\n",
    "\n",
    "def save_result(result_data, output_dir, output_filename):\n",
    "    \"\"\"\n",
    "    Save the results to a CSV file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    df = pd.DataFrame(result_data)\n",
    "    df.to_csv(os.path.join(output_dir, output_filename), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21172b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_brain_dict = collate_result_dict_list(all_input_dict_list)\n",
    "recon_brain_dict = collate_result_dict_list(all_recon_dict_list)\n",
    "label = torch.cat(all_image_index_list, dim=0).cpu().numpy()\n",
    "\n",
    "output_path = \"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/results/deeprecon/conversion/\"\n",
    "\n",
    "pattern_corr_result = []\n",
    "profile_corr_result = []\n",
    "\n",
    "for subj_target, subj_source in permutations(subj_list, 2):\n",
    "    s_t = f\"{int(subj_target):02d}\"\n",
    "    s_s = f\"{int(subj_source):02d}\"\n",
    "\n",
    "    target_brain = input_brain_dict[f\"x{s_t}\"]\n",
    "    recon_brain = recon_brain_dict[f\"cross_recon_x{s_t}__x{s_s}\"]\n",
    "\n",
    "    pattern_corr = calculate_pattern_correlation(target_brain, recon_brain, label)\n",
    "    for i, corr in enumerate(pattern_corr):\n",
    "        pattern_corr_result.append({\n",
    "            'Subject_target': subj_target, \n",
    "            'Subject_source': subj_source,           \n",
    "            'Correlation': corr, \n",
    "            'Image_idx': i+1}\n",
    "        )\n",
    "\n",
    "    profile_corr = calculate_profile_correlation(target_brain, recon_brain, label)\n",
    "    for i, corr in enumerate(profile_corr):\n",
    "        profile_corr_result.append({\n",
    "            'Subject_target': subj_target, \n",
    "            'Subject_source': subj_source,           \n",
    "            'Correlation': corr, \n",
    "            'Voxel_idx': i}\n",
    "        )\n",
    "\n",
    "save_result(pattern_corr_result, output_path, f\"pattern_correlation_dmvae_subj{''.join(map(str, subj_list))}.csv\")\n",
    "save_result(profile_corr_result, output_path, f\"profile_correlation_dmvae_subj{''.join(map(str, subj_list))}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e95826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastl2lir import FastL2LiR\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "\n",
    "from fmri_reconstruction_with_dmvae.deeprecon.datasets.load import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf910fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/data/deeprecon/\"\n",
    "conversion_output_path = \"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/results/deeprecon/conversion/\"\n",
    "subj_list = [1, 2, 3, 4, 5]  # [1, 2, 3, 4, 5]\n",
    "\n",
    "num_samples = 2400\n",
    "\n",
    "# set needed repetitions\n",
    "rep = 1 if num_samples < 1200 else int(num_samples / 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9df41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "train_brain_data_dict, test_brain_data_dict, all_subj_num_voxels = load_data(data_path, subj_list)\n",
    "\n",
    "### Load model params from \"https://github.com/KamitaniLab/InterIndividualDeepImageReconstruction/blob/main/ridge_ncc/params/converter_params.csv\"\n",
    "csv_path = \"/home/acg17270jl/projects/fmri-reconstruction-with-dmvae/checkpoints/deeprecon/converter_regression/converter_params.csv\"\n",
    "\n",
    "converter_params_df = pd.read_csv(csv_path).query(\"Method == 'wholeVC'\")\n",
    "\n",
    "converter_params_df = converter_params_df.assign(\n",
    "    Source=lambda x: x[\"Source\"].str.extract(r\"(\\d+)\", expand=False),\n",
    "    Target=lambda x: x[\"Target\"].str.extract(r\"(\\d+)\", expand=False),\n",
    ")\n",
    "\n",
    "target_num = converter_params_df[\"Target\"].astype(int)\n",
    "source_num = converter_params_df[\"Source\"].astype(int)\n",
    "order = np.lexsort([source_num, target_num])\n",
    "converter_params_df = converter_params_df.iloc[order]\n",
    "\n",
    "converter_params_df = converter_params_df[[\"Target\"] + [c for c in converter_params_df.columns if c != \"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8a8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(data_dict, s, rep=None):\n",
    "    data = data_dict[f\"subj{s}\"].select(\"ROI_VC\")\n",
    "    labels = data_dict[f\"subj{s}\"].select(\"image_index\")\n",
    "    sort_index = np.argsort(labels.flatten())\n",
    "    data = data[sort_index, :]\n",
    "    labels = labels[sort_index]\n",
    "\n",
    "    if rep is not None:\n",
    "        mask_unit = np.zeros(5, dtype=bool)\n",
    "        mask_unit[:rep] = True\n",
    "        mask = np.tile(mask_unit, 1200)\n",
    "        data = data[mask]\n",
    "        labels = labels[mask]\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def get_test(data_dict, s):\n",
    "    data = data_dict[f\"subj{s}\"].select(\"ROI_VC\")\n",
    "    labels = data_dict[f\"subj{s}\"].select(\"image_index\")\n",
    "    sort_index = np.argsort(labels.flatten())\n",
    "    data = data[sort_index, :]\n",
    "    labels = labels[sort_index]\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c609c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pattern_correlation(target_brain, recon_brain, label, rep=24):\n",
    "    sort_idx = np.argsort(label.flatten())\n",
    "    target_brain = target_brain[sort_idx]\n",
    "    recon_brain = recon_brain[sort_idx]\n",
    "    label = label[sort_idx]\n",
    "    unique_label = np.unique(label)\n",
    "\n",
    "    pattern_corr = []\n",
    "    for image_idx in unique_label:\n",
    "        target_pattern = target_brain[(label == image_idx).flatten(), :]\n",
    "        recon_pattern = recon_brain[(label == image_idx).flatten(), :]\n",
    "        \n",
    "        corrs = np.corrcoef(target_pattern, recon_pattern)[:rep, rep:]\n",
    "        corr = np.mean(corrs) \n",
    "\n",
    "        pattern_corr.append(corr)\n",
    "\n",
    "    return pattern_corr\n",
    "\n",
    "def calculate_profile_correlation(target_brain, recon_brain, label, rep=24):\n",
    "    sort_idx = np.argsort(label.flatten())\n",
    "    target_brain = target_brain[sort_idx]\n",
    "    recon_brain = recon_brain[sort_idx]\n",
    "\n",
    "    profile_corr = []\n",
    "    for voxel_idx in range(target_brain.shape[1]):\n",
    "        target_profile = target_brain[:, voxel_idx].reshape(rep, -1, order=\"F\")\n",
    "        recon_profile = recon_brain[:, voxel_idx].reshape(rep, -1, order=\"F\")\n",
    "        \n",
    "        corrs = np.corrcoef(target_profile, recon_profile)[:rep, rep:]\n",
    "        corr = np.mean(corrs) \n",
    "\n",
    "        profile_corr.append(corr)\n",
    "\n",
    "    return profile_corr\n",
    "\n",
    "def save_result(result_data, output_dir, output_filename):\n",
    "    \"\"\"\n",
    "    Save the results to a CSV file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    df = pd.DataFrame(result_data)\n",
    "    df.to_csv(os.path.join(output_dir, output_filename), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f860632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_corr_result = []\n",
    "profile_corr_result = []\n",
    "\n",
    "for subj_target, subj_source in permutations(subj_list, 2):\n",
    "    s_t = f\"{int(subj_target):02d}\"\n",
    "    s_s = f\"{int(subj_source):02d}\"\n",
    "\n",
    "    # === Train ===\n",
    "    x_train, x_train_labels = get_train(train_brain_data_dict, s_s, rep)\n",
    "    y_train, y_train_labels = get_train(train_brain_data_dict, s_t, rep)\n",
    "\n",
    "    # normalize\n",
    "    x_train_mean = np.mean(x_train, axis=0)[np.newaxis, :]\n",
    "    x_train_norm = np.std(x_train, axis=0, ddof=1)[np.newaxis, :]\n",
    "    x_train_normalized = (x_train - x_train_mean) / x_train_norm\n",
    "    y_train_mean = np.mean(y_train, axis=0)[np.newaxis, :]\n",
    "    y_train_norm = np.std(y_train, axis=0, ddof=1)[np.newaxis, :]\n",
    "    y_train_normalized = (y_train - y_train_mean) / y_train_norm\n",
    "\n",
    "    # fit\n",
    "    model = FastL2LiR()\n",
    "    alpha = converter_params_df.set_index([\"Target\", \"Source\", \"Number of samples\"]).at[(f\"{s_t}\", f\"{s_s}\", num_samples), \"Alpha\"]\n",
    "    model.fit(x_train_normalized,  y_train_normalized, alpha=780, n_feat=x_train_normalized.shape[1], chunk_size=0, dtype=np.float32)\n",
    "\n",
    "\n",
    "    # === Test ===\n",
    "    x_test, x_test_labels = get_test(test_brain_data_dict, s_s)\n",
    "    y_test, y_test_labels = get_test(test_brain_data_dict, s_t)\n",
    "\n",
    "    # normalize\n",
    "    x_test_normalized = (x_test - x_train_mean) / x_train_norm\n",
    "    y_test_normalized = (y_test - y_train_mean) / y_train_norm\n",
    "\n",
    "    # predict\n",
    "    converted_x_test_normalized = model.predict(x_test_normalized)\n",
    "\n",
    "\n",
    "    # === Evaluation ===\n",
    "    pattern_corr = calculate_pattern_correlation(y_test_normalized, converted_x_test_normalized, x_test_labels)\n",
    "    for i, corr in enumerate(pattern_corr):\n",
    "        pattern_corr_result.append({\n",
    "            'Subject_target': subj_target, \n",
    "            'Subject_source': subj_source,           \n",
    "            'Correlation': corr, \n",
    "            'Image_idx': i+1}\n",
    "        )\n",
    "\n",
    "    profile_corr = calculate_profile_correlation(y_test_normalized, converted_x_test_normalized, x_test_labels)\n",
    "    for i, corr in enumerate(profile_corr):\n",
    "        profile_corr_result.append({\n",
    "            'Subject_target': subj_target, \n",
    "            'Subject_source': subj_source,           \n",
    "            'Correlation': corr, \n",
    "            'Voxel_idx': i}\n",
    "        )\n",
    "\n",
    "save_result(pattern_corr_result, conversion_output_path, \"pattern_correlation_converter_regression.csv\")\n",
    "save_result(profile_corr_result, conversion_output_path, \"profile_correlation_converter_regression.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
